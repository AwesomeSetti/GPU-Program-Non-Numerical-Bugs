Project,Repo Stars,Contributors,Closed Issues,Bug Title,Data Type,Root Cause,Subcategory,Symptom,Subcategory,Fixing Stratgy,Description
NVIDIA/CUTLASS,?8.2?k,199,333,[BUG]cute::_ and _ in C+= structured binding used together cause runtime issues. #2498 ,float,Data Type and Operator Bug,Data Type issue,Error Message,Overflow/Underflow,Add data type support or change data types(Reduce tile size or increase SMEM),GEMM kernel fails with a CUDA “out of resources” error when K is large because shared memory requirements exceed GPU  limits. Adjusting tile size or memory allocation is the solution.
NVIDIA/CUTLASS,?8.2?k,199,333,[Bug] Incorrect benchmark of cuteDsl/ampere/elementwise_apply.py #2339 ,"	float",Data Type and Operator Bug,Operator Bugs,Error Message,Operator,"	Refactor Operator Implementation","CUTLASS crashes in prefetch_epilog, due to unsafe logic during GEMM kernel epilog. Fix involved correcting predicate/load behavior in the operator backend."
NVIDIA/CUTLASS,?8.2?k,199,333,[bug] [CuTe DSL] for loop is wrong if step is negative #2326,,Data Type and Operator Bug,Data Type Bugs,Error Message,Data Type,"	Add Data Type Support or Change Data Type",Attempting to use fp8 as output in CUTLASS’s LinearCombination causes a compile error due to unsupported type traits. Requires adding fp8 support or switching types.
NVIDIA/CUTLASS,?8.2?k,199,333,[BUG] [BUG] Precision issue with python cutlass gemm #2014,NaN,Precision Bugs,Casting Bugs,"	Wrong Results",Upcasting/Downcasting Strategies,Upcast/Downcast Strategies,Adding float32 and int32 causes silent NaN output due to implicit casting
NVIDIA/CUTLASS,?8.2?k,199,333,"[BUG] #include ""cutlass/gemm/device/gemm_universal_adapter.h"" is causing the named symbol to not be found #1811",float16,Precision Bugs,Rounding/Approximation Bugs,Wrong Results,Different Precision Range,Change Precision,GEMM with float16 inputs and certain tiling configs produces wrong results; mixed precision fixes issue
apache/tvm,11.6?k,786,5300,"[Bug]
",int,Data Type and Operator Bugs,Data Type Bugs,Error Message,Data Type,Refactor operator / fix IR transformation,"the bug occurs in TileWithTensorIntrin when it calls PadEinsum and inlines padded inputs/outputs into their producers/consumers. If an input/output does not need padding, the transformation may inline irrelevant blocks, causing invalid accesses and a segfault. The fix is to track which producers/consumers are padded by PadEinsum and inline only those.
"
apache/tvm,11.6?k,786,5300,[Bug] Tensorization Failure During Multilevel Tiling with Tensor Intrin #16614 ,float,"	Data Type and Operator Bugs",Operator issue,Error Message,Operator,"	Refactor Operator Implementation","TileWithTensorIntrin inlined blocks that were not actually padded, due to incorrect logic in PadEinsum. This caused a segmentation fault during execution. The fix tracks which producers/consumers are padded and only inlines those."
apache/tvm,11.6?k,786,5300,[Bug] BuiltinLower has hard-coded heuristic for alloca which is not appropriate for all kDLCPU target devices #9022,float64,Precision Bugs,Rounding/Approximation Bugs,Wrong Results,Different Precision Range,Change Precision,float64 reduction on CUDA in TVM yields incorrect results due to faulty accumulation. Fix involved adjusting precision handling during GPU execution.
apache/tvm,11.6?k,786,5300,[Bug] LegalizeOps fails to process LayerNormalization of valid onnx model: tvm.error.InternalError: Check failed: shape.size() == indices.size() (1 vs. 0) #18002,float16,Precision Bugs,Arithmetic Operation Bugs,Wrong Results,Different Precision Range,Change Precision,te.lang.cce.vadd with float16 large tensor size gives incorrect results on Ascend backend; mixed precision likely fixes
apache/tvm,11.6?k,786,5300,[Bug] Mismatched Elements between TVM and ONNXRuntime #17988 ,float16,Precision Bugs,Rounding/Approximation Bugs,Wrong Results,Different Precision Range,Change Precision,"	On CUDA backend, topk with float16 inputs produces incorrect results vs CPU; float32 resolves mismatch"
Triton,7.5k,125,670,[BUG] Numerical mismatch between custom Triton kernel and PyTorch reference implementation #7045,Nan,Data Type and Operator Bugs,Data Type Bugs,"	Wrong Results",NaN Outputs,"	Add Data Type Support or Change Data Type",Mixing int32 with float16 in Triton causes NaN values. This occurs due to unsupported implicit casting or incompatible operation. Fixing this requires enforcing valid type rules or adding explicit casts.
Triton,7.5k,125,670,"[BUG] Low GLIBC limits bitsandbytes to 0.42.0 (causing Triton issues), while source-compiled newer bitsandbytes lacks __version__ attribute #6783","	float",Data Type and Operator Bugs,Operator Bugs,Wrong Results,NaN Outputs,"	Refactor Operator Implementation","Dividing by a constant float like 1.442695... causes NaN in Triton, unlike in PyTorch or NumPy. This indicates a backend bug in how constants or float ops are handled."
Triton,7.5k,125,670,[BUG] Matmul kernel precision mismatch #6265 ,fp16 + int32,Data Type and Operator Bugs,Data Type Bugs,Wrong Results,Different data types,"	Add Data Type Support or Change Data Type",Adding fp16 and int32 tensors fails silently in Triton without error or output. This is a data type mismatch and should be flagged during compilation or casting.
Triton,7.5k,125,670,[BUG] Float operation -- numerical accuracy #6221 ,float,Precision Bugs,Rounding/Approximation Bugs,Wrong Results,Different Precision Range,Change Precision,"Triton promotes float32 + float64 to float32, which contradicts NumPy and causes loss of precision. This bug stems from incorrect promotion rules and can be fixed by preserving higher precision in mixed operations."
Triton,7.5k,125,670,[BUG] tl.dot output is different from torch.mm #5849 ,float32 + int32,Data Type and Operator Bugs,Data Type Bugs,Wrong Results,Different data types,"	Add Data Type Support or Change Data Type","Triton incorrectly computes float32 + int32, producing wrong numerical results without warnings. This occurs due to improper type promotion or validation in the JIT compiler."
Triton,7.5k,125,670,[BUG] Triton does not really enable -ftz #5735 ,float32 + int32,Data Type and Operator Bugs,Data Type Bugs,Wrong Results,Different Data Types,Add Data Type Support or Change Data Type,Dot product between float16 and int32 compiles in Triton but produces incorrect values compared to NumPy. This indicates a type promotion or compatibility error in the kernel’s implementation.
Triton,7.5k,125,670,[BUG] in MaxMinOpAxisInfoVisitor #7758 ,float16,Data Type and Operator Bugs,Data Type Bugs,Wrong Results,NaN Outputs,"	Refactor Operator Implementation","Using masked loads to fetch float16 values in Triton causes NaN outputs. The bug is likely in the operator logic or backend lowering, and needs a fix to correctly handle masked memory access."
Triton,7.5k,125,670,[Bug] Triton 3.4.0 + Torch 2.8.0 not working correctly #7594,float32,Data Type and Operator Bugs,Operator Bugs,Wrong Results,NaN Outputs,Refactor Operator Implementation,Triton kernel incorrectly returns NaN when assigning float32(1.0). The bug was caused by IR backend mishandling constant values and was fixed by correcting SSA propagation.
Triton,7.5k,125,670,[BUG] Numerical mismatch between custom Triton kernel and PyTorch reference implementation #7045,Nan,Data Type and Operator Bugs,Data Type Bugs,Wrong Results,NaN Outputs,"	Add Data Type Support or Change Data Type",Multiplying int32 and float16 tensors in Triton returns NaN instead of promoting the types or throwing an error. This stems from an unsupported mixed-type operation and requires type handling logic.
CuPy,10.4k,399,1994,[BUG] launch_host_func doesn't work with CUDA Graph #9274 ,float32,Data Type and Operator Bugs,Data Type Bugs,Error Message,Casting,Add data type support / cast inputs,Mismatch in input dtypes triggers error; NumPy auto-aligns but CuPy does not
CuPy,10.4k,399,1994,[BUG] cupy.nanargmax gives different results with/without out #8784 ,float16,Precision Bugs,Rounding/Approximation Bugs,Wrong Results,Different amount of precision,Change Precision ,CuPy returns zeros with float16 interpolation while SciPy returns correct values
CuPy,10.4k,399,1994,[BUG] cupy.nanargmin triggers an error when array is [[0.]] and out is used #8782,float64,Data Type and Operator Bugs,Operator Bugs,Error Message,Operator,"	Refactor Operator Implementation",cupy.mean used in generic_filter raises error while numpy.mean works fine
CuPy,10.4k,399,1994,[Bug] inf and nan is undefined in jit.rawkernel #8696,float16,Data Type and Operator Bugs,Data Type Bugs,Error Message,Different data types,Add Data Type Support / Change Type,cp.corrcoef crashes on float16 input; NumPy accepts it — shows CuPy's missing type support
CuPy,10.4k,399,1994,[BUG]argmax overflows for large arrays #8014 ,float32,Precision Bugs,Rounding/Approximation Bugs,Wrong Results,Different Precision Range,Change Precision ,cupy.linalg.eigh produces inaccurate results for float32; float64 fixes it — rounding issue
CuPy,10.4k,399,1994,[bug] stride_tricks.as_strided and advanced indexing don't play well with each other. #8130,float32,Precision Bugs,Rounding/Approximation Bugs,Wrong Results,Different amount of precision,Change Precision ,"cp.interp returns 1.0, while NumPy returns 1.5 for same input — discrepancy due to rounding"
CuPy,10.4k,399,1994,[Bug] Fix cuRAND lazy load issue #8018 ,float16,Data Type and Operator Bugs,Data Type Bugs,Error Message,Data Type,Add Data Type Support / Change Type,cp.linalg.svd raises exception on float16 input; NumPy works — indicates missing type support in CuPy
CuPy,10.4k,399,1994,[BUG] Indexing sparse_matrix_A[sparse_matrix_B] only works if sparse_matrix_B is on CPU #7750,float32,Data Type and Operator Bugs,Data Type Bugs,Error Message,Data Type,Add Data Type Support / Change Type,Indexing fails when the index sparse matrix is on GPU; works on CPU — indicates missing type support in CuPy
CuPy,10.4k,399,1994,[bug] Cupy's searchsorted sometimes deviates from numpy's outcome #7639 ,float64,Precision Bugs,Rounding/Approximation Bugs,Wrong Results,Different amount of precision,"	Refactor Operator Implementation","For cp.arange(1,3,0.1, dtype=float64) and query 2, NumPy returns 10 while CuPy returns 11—rounding/ordering mismatch in searchsorted."
CuPy,10.4k,399,1994,[BUG] cupyx.scipy.sparse.csr_matrix of dtype bool behaves different from scipy.sparse.csr_matrix #7713,float16,Precision Bugs,Rounding/Approximation Bugs,Wrong Results,Different amount of precision,Change Precision ,CuPy's percentile on float16 gives different results vs NumPy; float64 fixes discrepancy
CuPy,10.4k,399,1994,[BUG] Cupy's searchsorted sometimes deviates from numpy's outcome #7639,float64,Precision Bugs,Rounding/Approximation Bugs,Wrong Results,Different amount of precision,"	Refactor Operator Implementation",searchsorted on float64 returns index 11 in CuPy vs 10 in NumPy for same inputs; caused by float comparison rounding
CuPy,10.4k,399,1994,[bug] RAM memory leak while using a RawKernel with large input array (~ 2 GB) #7914,,Memory Bugs,Host RAM leak,Performance/Resource Issue,Memory usage growth over time,Ensure host-side allocations are freed; audit RawKernel launch wrappers; reuse buffers; profile with tracemalloc,"Repeated RawKernel calls with 2?GB inputs increase host RAM continuously, suggesting a leak in host?side buffers or Python/CuPy wrappers"
CuPy,10.4k,399,1994,[bug] Sums on large arrays fails to calculate the proper result #9186,float16,Precision Bugs,Rounding/Approximation Bugs,Wrong Results,Different amount of precision,Change Precision ,"	cupy.einsum with float16 inputs gives inaccurate results vs NumPy; higher precision types match expected output"
CuPy,10.4k,399,1994,[bug] cupy.linalg.pinv behaves differently with numpy.linalg.pinv #9085 ,float16,Precision Bugs,Rounding/Approximation Bugs,Wrong Results,Different amount of precision,Change Precision ,cupy.polyval on float16 produces inaccurate results vs NumPy; higher precision types match expected output
CuPy,10.4k,399,1994,[bug] LinearNDInterpolator / Delaunay: Illegal Memory Access #8933 ,float16,Precision Bugs,Rounding/Approximation Bugs,Wrong Results,Different amount of precision,Change Precision ,cupy.histogram with float16 inputs produces inaccurate bin counts vs NumPy; higher precision resolves discrepancy
CuPy,10.4k,399,1994,[bug] torch.cuda.current_device() is changed by CuPy after 10.0 #6569 ,None,Device-specific Bugs,Device-specific Bugs,Wrong Results,Different Data Types,Add Data Type Support / Change Type,"After CuPy 10.0, using with cupy.cuda.Device(n): changes the global torch.cuda.current_device() in PyTorch after the context exits. This silent state change breaks multi-GPU workflows . The fix restores the previous active device after leaving the CuPy context so other frameworks retain their expected device state."
Tensorflow,191k,2k,8.7k,[bug] ValueError: in user code: #98199 ,uint8,Precision Bugs,Rounding/Approximation Bugs,Wrong Results,Different amount of precision,"	Refactor Operator Implementation","On GPU, tf.image.adjust_jpeg_quality with uint8 images produces outputs that differ from CPU results; caused by precision/rounding differences in GPU implementation"
Tensorflow,191k,2k,8.7k,[bug] Tensor Flow import Error #98359 ,uint8,Precision Bugs,Rounding/Approximation Bugs,Wrong Results,Different amount of precision,"	Refactor Operator Implementation","On GPU, tf.image.adjust_brightness with uint8 images produces output that differs from CPU results due to precision/rounding differences in GPU implementation"
Tensorflow,191k,2k,8.7k,"[BUG] tf.transpose crashes with negative perm value: ""Check failed: d >= 0 (0 vs. -1)"" #94433",float16,Precision Bugs,Rounding/Approximation Bugs,Wrong Results,Different amount of precision,Change Precision ,tf.reduce_sum with float16 inputs produces different results on GPU compared to CPU due to precision and accumulation order differences; float32 accumulation resolves issue
Tensorflow,191k,2k,8.7k,[BUG] graph execution error bug with tfm.nlp.layers.MultiHeadRelativeAttention #94599,float16,Precision Bugs,Rounding/Approximation Bugs,Wrong Results,Different amount of precision,Change Precision ,tf.math.divide using float16 yields output differences between GPU and CPU due to rounding/precision behavior; using float32 eliminates the discrepancy
Tensorflow,191k,2k,8.7k,"[bug] . Suggested fix A: If you wish to use DenseFeatures, use a non-sequence categorical_column_with_*. Suggested fix B: If you wish to create sequence input, use #98203",uint8,Precision Bugs,Rounding/Approximation Bugs,Wrong Results,Different amount of precision,"	Refactor Operator Implementation","On GPU, tf.image.adjust_gamma with uint8 images yields results that differ from CPU outputs due to rounding and precision differences in GPU implementation"
Tensorflow,191k,2k,8.7k,[BUG] Critical Bug: Quantization Fails on Custom LSTM Models in Model Optimization Library #94101,float16,Precision Bugs,Rounding/Approximation Bugs,Wrong Results,Different amount of precision,Change Precision ,tf.image.resize using float16 inputs produces output discrepancies between GPU and CPU due to precision and rounding differences; float32 resolves mismatch
Tensorflow,191k,2k,8.7k,[bug] TensorFlow tf.scatter_nd leads to crash via shape mismatch in indices input #93679,uint8,Precision Bugs,Rounding/Approximation Bugs,Wrong Results,Different amount of precision,"	Refactor Operator Implementation",tf.image.rot90 with uint8 images produces differing results between GPU and CPU backends due to rounding and pixel value handling differences
rapidsai/cuml,3.9k,270,4200,[BUG] RandomForestClassifier crashes the process for check_classifiers_regression_target #7064,float32,Precision Bugs,Rounding/Approximation Bugs,Wrong Results,Different amount of precision,Change Precision ,"In PolynomialFeatures, GPU float32 expansion produces slight coefficient differences in the generated polynomial terms, causing mismatched values in higher-degree interaction terms compared to CPU. This stems from rounding differences in repeated multiplications of float32 features."
rapidsai/cuml,3.9k,270,4200,[BUG] RandomForestClassifier predict crashes with floating point exception on very wide inputs #7010,float32,Precision Bugs,Rounding/Approximation Bugs,Wrong Results,Different amount of precision,Change Precision ,"In TruncatedSVD, GPU float32 singular value decomposition yields slightly different singular vectors and values from CPU, leading to variations in projected data. This is due to rounding error accumulation during iterative SVD approximation on GPU."
rapidsai/cuml,3.9k,270,4200,[bug][BUG] AutoGluon LogisticRegression breaks with cuml.accel #6909 ,float32,Precision Bugs,Rounding/Approximation Bugs,Wrong Results,Different amount of precision,Change Precision ,"For PCA with float32, GPU computation of covariance and eigen decomposition introduces small rounding differences, altering eigenvalues and explained variance ratios compared to CPU. Differences are amplified by the ordering of floating-point operations in GPU kernels."
rapidsai/cuml,3.9k,270,4200,[BUG] UMAP spectral init fails to converge under certain conditions #6743,float32,Precision Bugs,Rounding/Approximation Bugs,Wrong Results,Different amount of precision,Change Precision ,"In UMAP with float32 inputs, GPU’s approximate nearest-neighbor search and stochastic gradient descent steps accumulate rounding errors differently than CPU, leading to shifts in the low-dimensional embedding layout."
rapidsai/cuml,3.9k,270,4200,"[BUG] KNeighborsClassifier fails with weights=""distance"" in cuml.accel #6545",float32,Precision Bugs,Rounding/Approximation Bugs,Wrong Results,Different amount of precision,Change Precision ,"KMeans, GPU float32 distance calculations and centroid updates produce slightly different intermediate results from CPU. These differences shift centroid positions over iterations, occasionally changing final cluster assignments."
rapidsai/cuml,3.9k,270,4200,"cuSOLVER error encountered when running rsc.pp.pca(adata, n_comps=50) #6182",float32,Precision Bugs,Rounding/Approximation Bugs,Wrong Results,Different amount of precision,Change Precision ,"In DBSCAN with float32, GPU rounding differences in pairwise distance calculations alter neighborhood counts, which can change whether points meet the density threshold for forming a cluster, leading to label mismatches with CPU"
rapidsai/cuml,3.9k,270,4200,[BUG] - cuML LabelEncoder is 200x slower with cuDF-Pandas vs cuDF #6232," 	string",Performance Bugs,Data Movement Overhead,Performance Bottleneck,CPU Programs,Optimize data handling,"	Using cuDF-Pandas DataFrame as input to cuML LabelEncoder forces CPU-side processing, causing ~200× slowdown compared to pure cuDF DataFrame"
rapidsai/cuml,3.9k,270,4200,[BUG] Batched nn-descent UMAP unexpectedly throws OOM error on dataset that should succeed with UVM #6204,float32,Data Type and Operator Bugs,Data Type Bugs,Performance Bottleneck,CPU Programs,Optimize data handling,KNN with float32 inputs runs slower on GPU than CPU for small datasets due to kernel launch overhead and CPU-side processing dominating execution time
